{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "591e6881",
   "metadata": {},
   "source": [
    "#### Loss type\n",
    "there are different loss type: margin, softplus etc, but not clear yet what exactly they are"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97c6691",
   "metadata": {},
   "source": [
    "#### tail prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed270b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.models.predict import get_tail_prediction_df\n",
    "\n",
    "df = get_tail_prediction_df(\n",
    "    model=result.model,\n",
    "    head_label=\"belgium\",\n",
    "    relation_label=\"locatedin\",\n",
    "    triples_factory=result.training,\n",
    "    add_novelties=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7d34d8",
   "metadata": {},
   "source": [
    "#### ranking tier\n",
    "- The optimistic rank assumes that the true choice is on the first position of all those with equal score.\n",
    "\n",
    "- The pessimistic rank assumes that the true choice is on the last position of all those with equal score.\n",
    "\n",
    "- The realistic rank is the mean of the optimistic and the pessimistic rank, and moreover the expected value over all permutations respecting the sort order.\n",
    "\n",
    "- The non-deterministic rank delegates the decision to the sort algorithm. Thus, the result depends on the internal tie breaking mechanism of the sort algorithmâ€™s implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12918a8",
   "metadata": {},
   "source": [
    "#### sure about this? \n",
    "When early stopping is used during training, it periodically uses the validation set for calculating the loss and evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6213f3b9",
   "metadata": {},
   "source": [
    "### pipeline should not be directly used:\n",
    "pykeen.pipeline.pipeline() that has no optimization, no early stopping, nor any post-hoc choices using the validation set, the set of known positive triples comprises the training and testing sets. This scenario is very atypical, and regardless, should be augmented with the validation triples to make more comparable to other published results that do not consider this scenario.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe22496",
   "metadata": {},
   "source": [
    "#### Using pipeline about validation:\n",
    "In case the validation triples should not be filtered when evaluating the test dataset, the argument filter_validation_when_testing=False can be passed to either the pykeen.hpo.hpo_pipeline() or pykeen.pipeline.pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa89ead",
   "metadata": {},
   "source": [
    "### Example of valuate specific relations only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72bac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.pipeline import pipeline\n",
    "\n",
    "evaluation_relation_whitelist = {'CtD', 'CpD'}\n",
    "pipeline_result = pipeline(\n",
    "    dataset='Hetionet',\n",
    "    model='RotatE',\n",
    "    evaluation_relation_whitelist=evaluation_relation_whitelist,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd0b15a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acac4f60",
   "metadata": {},
   "source": [
    "### Optimization\n",
    "use hpo_pipeline for optimization, which may have model specific range or default range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d069f9c",
   "metadata": {},
   "source": [
    "if to set optimization range example one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df80b8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.hpo import hpo_pipeline\n",
    "hpo_pipeline_result = hpo_pipeline(\n",
    "    dataset='Nations',\n",
    "    model='TransE',\n",
    "    model_kwargs_ranges=dict(\n",
    "        embedding_dim=dict(type=int, low=16, high=256, step=32),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478de353",
   "metadata": {},
   "source": [
    "during optimization set number of trails or time out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688e4bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.hpo import hpo_pipeline\n",
    "hpo_pipeline_result = hpo_pipeline(\n",
    "    n_trials=30,  or timeout=60\n",
    "    dataset='Nations',\n",
    "    model='TransE',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5572a3",
   "metadata": {},
   "source": [
    "example set fix value during optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02626df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.hpo import hpo_pipeline\n",
    "hpo_pipeline_result = hpo_pipeline(\n",
    "    model='TransE',\n",
    "    model_kwargs=dict(\n",
    "        embedding_dim=200,\n",
    "    ),\n",
    "    dataset='Nations',\n",
    "    n_trials=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcbf07b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20b0785e",
   "metadata": {},
   "source": [
    "early stopping in hpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bbcb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.hpo import hpo_pipeline\n",
    "hpo_pipeline_result = hpo_pipeline(\n",
    "    n_trials=30,\n",
    "    dataset='Nations',\n",
    "    model='TransE',\n",
    "    stopper='early',\n",
    "    stopper_kwargs=dict(frequency=5, patience=2, relative_delta=0.002),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac244c3",
   "metadata": {},
   "source": [
    "example of use grid search in optimization--> less efficent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5293503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.hpo import hpo_pipeline\n",
    "from optuna.samplers import GridSampler\n",
    "hpo_pipeline_result = hpo_pipeline(\n",
    "    n_trials=30,\n",
    "    sampler=GridSampler,\n",
    "    sampler_kwargs=dict(\n",
    "        search_space={\n",
    "            \"model.embedding_dim\": [32, 64, 128],\n",
    "            \"model.scoring_fct_norm\": [1, 2],\n",
    "            \"loss.margin\": [1.0],\n",
    "            \"optimizer.lr\": [1.0e-03],\n",
    "            \"negative_sampler.num_negs_per_pos\": [32],\n",
    "            \"training.num_epochs\": [100],\n",
    "            \"training.batch_size\": [128],\n",
    "        },\n",
    "    ),\n",
    "    dataset='Nations',\n",
    "    model='TransE',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5cf4dd",
   "metadata": {},
   "source": [
    "#### Full setting  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c569df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.hpo import hpo_pipeline_from_config\n",
    "config = {\n",
    "    'optuna': dict(\n",
    "        n_trials=30,\n",
    "    ),\n",
    "    'pipeline': dict(\n",
    "        dataset='Nations',\n",
    "        model='TransE',\n",
    "        model_kwargs=dict(embedding_dim=20, scoring_fct_norm=1),\n",
    "        optimizer='SGD',\n",
    "        optimizer_kwargs=dict(lr=0.01),\n",
    "        loss='marginranking',\n",
    "        loss_kwargs=dict(margin=1),\n",
    "        training_loop='slcwa',\n",
    "        training_kwargs=dict(num_epochs=100, batch_size=128),\n",
    "        negative_sampler='basic',\n",
    "        negative_sampler_kwargs=dict(num_negs_per_pos=1),\n",
    "        evaluator_kwargs=dict(filtered=True),\n",
    "        evaluation_kwargs=dict(batch_size=128),\n",
    "        stopper='early',\n",
    "        stopper_kwargs=dict(frequency=5, patience=2, relative_delta=0.002),\n",
    "    )\n",
    "}\n",
    "hpo_pipeline_result = hpo_pipeline_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c523494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.hpo import hpo_pipeline\n",
    "hpo_pipeline_result = hpo_pipeline(\n",
    "    n_trials=30,\n",
    "    dataset='Nations',\n",
    "    model='TransE',\n",
    "    model_kwargs=dict(embedding_dim=20, scoring_fct_norm=1),\n",
    "    optimizer='SGD',\n",
    "    optimizer_kwargs=dict(lr=0.01),\n",
    "    loss='marginranking',\n",
    "    loss_kwargs=dict(margin=1),\n",
    "    training_loop='slcwa',\n",
    "    training_kwargs=dict(num_epochs=100, batch_size=128),\n",
    "    negative_sampler='basic',\n",
    "    negative_sampler_kwargs=dict(num_negs_per_pos=1),\n",
    "    evaluator_kwargs=dict(filtered=True),\n",
    "    evaluation_kwargs=dict(batch_size=128),\n",
    "    stopper='early',\n",
    "    stopper_kwargs=dict(frequency=5, patience=2, relative_delta=0.002),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32983220",
   "metadata": {},
   "source": [
    "#### Prediction example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1fd96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from pykeen.pipeline import pipeline\n",
    ">>> from pykeen.models import predict\n",
    ">>> # Run the pipeline\n",
    ">>> result = pipeline(dataset='Nations', model='RotatE')\n",
    ">>> # save the model\n",
    ">>> result.save_to_directory('doctests/nations_rotate')\n",
    ">>> model = result.model\n",
    ">>> # Predict tails\n",
    ">>> predicted_tails_df = predict.get_tail_prediction_df(\n",
    "...    model, 'brazil', 'intergovorgs', triples_factory=result.training,\n",
    "... )\n",
    ">>> # Predict relations\n",
    ">>> predicted_relations_df = predict.get_relation_prediction_df(\n",
    "...    model, 'brazil', 'uk', triples_factory=result.training,\n",
    "... )\n",
    ">>> # Predict heads\n",
    ">>> predicted_heads_df = predict.get_head_prediction_df(model, 'conferences', 'brazil', triples_factory=result.training)\n",
    ">>> # Score all triples (memory intensive)\n",
    ">>> predictions_df = predict.get_all_prediction_df(model, triples_factory=result.training)\n",
    ">>> # Score top K triples\n",
    ">>> top_k_predictions_df = predict.get_all_prediction_df(model, k=150, triples_factory=result.training)\n",
    ">>> # Score a given list of triples\n",
    ">>> score_df = predict.predict_triples_df(\n",
    "...    model=model,\n",
    "...    triples=[('brazil', 'conferences', 'uk'), ('brazil', 'intergovorgs', 'uk')],\n",
    "...    triples_factory=result.training,\n",
    "... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2415c15e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b5f81c4",
   "metadata": {},
   "source": [
    "#### Example of create optimization beyond hpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc38ee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "directory = \"doctests/ablation/ex05_stopper\"\n",
    ">>> ablation_pipeline(\n",
    "...    directory=directory,\n",
    "...    models=[\"ComplEx\"],\n",
    "...    datasets=[\"Nations\"],\n",
    "...    losses=[\"BCEAfterSigmoidLoss\", \"MarginRankingLoss\"],\n",
    "...    training_loops=[\"LCWA\"],\n",
    "...    optimizers=[\"Adam\"],\n",
    "...    stopper = \"early\",\n",
    "...    stopper_kwargs = {\n",
    "...        \"frequency\": 5,\n",
    "...        \"patience\": 20,\n",
    "...        \"relative_delta\": 0.002,\n",
    "...        \"metric\": \"hits@10\",\n",
    "...    },\n",
    "...    # Fast testing configuration, make bigger in prod\n",
    "...    epochs=1,\n",
    "...    n_trials=1,\n",
    "... )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f36bca",
   "metadata": {},
   "source": [
    "#### Full example of ablation + hpo example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374f528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from pykeen.ablation import ablation_pipeline\n",
    ">>> metadata = dict(title=\"Ablation Study Over Nations for ComplEx.\")\n",
    ">>> models = [\"ComplEx\"]\n",
    ">>> datasets = [\"Nations\"]\n",
    ">>> losses = [\"BCEAfterSigmoidLoss\"]\n",
    ">>> training_loops = [\"lcwa\"]\n",
    ">>> optimizers = [\"adam\"]\n",
    ">>> create_inverse_triples= [True, False]\n",
    ">>> stopper = \"early\"\n",
    ">>> stopper_kwargs = {\n",
    "...   \"frequency\": 5,\n",
    "...   \"patience\": 20,\n",
    "...   \"relative_delta\": 0.002,\n",
    "...   \"metric\": \"hits@10\",\n",
    "... }\n",
    "\n",
    "# Define HPO ranges\n",
    ">>> model_to_model_kwargs_ranges = {\n",
    "...   \"ComplEx\": {\n",
    "...       \"embedding_dim\": {\n",
    "...           \"type\": \"int\",\n",
    "...           \"low\": 4,\n",
    "...           \"high\": 6,\n",
    "...           \"scale\": \"power_two\"\n",
    "...       }\n",
    "...   }\n",
    "... }\n",
    "\n",
    ">>> model_to_training_loop_to_training_kwargs = {\n",
    "...   \"ComplEx\": {\n",
    "...       \"lcwa\": {\n",
    "...           \"num_epochs\": 50\n",
    "...       }\n",
    "...   }\n",
    "... }\n",
    "\n",
    ">>> model_to_training_loop_to_training_kwargs_ranges= {\n",
    "...   \"ComplEx\": {\n",
    "...       \"lcwa\": {\n",
    "...           \"label_smoothing\": {\n",
    "...               \"type\": \"float\",\n",
    "...               \"low\": 0.001,\n",
    "...              \"high\": 1.0,\n",
    "...               \"scale\": \"log\"\n",
    "...           },\n",
    "...           \"batch_size\": {\n",
    "...               \"type\": \"int\",\n",
    "...               \"low\": 7,\n",
    "...               \"high\": 9,\n",
    "...               \"scale\": \"power_two\"\n",
    "...           }\n",
    "...       }\n",
    "...   }\n",
    "... }\n",
    "\n",
    "\n",
    ">>> model_to_optimizer_to_optimizer_kwargs_ranges= {\n",
    "...   \"ComplEx\": {\n",
    "...       \"adam\": {\n",
    "...           \"lr\": {\n",
    "...               \"type\": \"float\",\n",
    "...               \"low\": 0.001,\n",
    "...               \"high\": 0.1,\n",
    "...               \"scale\": \"log\"\n",
    "...           }\n",
    "...       }\n",
    "...   }\n",
    "... }\n",
    "\n",
    "# Run ablation experiment\n",
    ">>> ablation_pipeline(\n",
    "...   models=models,\n",
    "...   datasets=datasets,\n",
    "...   losses=losses,\n",
    "...   training_loops=training_loops,\n",
    "...   optimizers=optimizers,\n",
    "...   model_to_model_kwargs_ranges=model_to_model_kwargs_ranges,\n",
    "...   model_to_training_loop_to_training_kwargs=model_to_training_loop_to_training_kwargs,\n",
    "...   model_to_optimizer_to_optimizer_kwargs_ranges=model_to_optimizer_to_optimizer_kwargs_ranges,\n",
    "...   directory=\"doctests/ablation/ex6\",\n",
    "...   best_replicates=5,\n",
    "...   n_trials=2,\n",
    "...   timeout=300,\n",
    "...   metric=\"hits@10\",\n",
    "...   direction=\"maximize\",\n",
    "...   sampler=\"random\",\n",
    "...   pruner=\"nop\",\n",
    "... )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d5d66e",
   "metadata": {},
   "source": [
    "#### Use transformer label:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7208cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.datasets import get_dataset\n",
    "from pykeen.nn.representation import EmbeddingSpecification, LabelBasedTransformerRepresentation\n",
    "from pykeen.models import ERModel\n",
    "\n",
    "dataset = get_dataset(dataset=\"nations\")\n",
    "entity_representations = LabelBasedTransformerRepresentation.from_triples_factory(\n",
    "    triples_factory=dataset.training,\n",
    ")\n",
    "result = pipeline(\n",
    "    dataset=dataset,\n",
    "    model=ERModel,\n",
    "    model_kwargs=dict(\n",
    "        interaction=\"ermlpe\",\n",
    "        interaction_kwargs=dict(\n",
    "            embedding_dim=entity_representations.embedding_dim,\n",
    "        ),\n",
    "        entity_representations=entity_representations,\n",
    "        relation_representations=EmbeddingSpecification(\n",
    "            shape=entity_representations.shape,\n",
    "        ),\n",
    "    ),\n",
    "    training_kwargs=dict(\n",
    "        num_epochs=1,\n",
    "    ),\n",
    ")\n",
    "model = result.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970c1559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92be1332",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fanbo_pykeen",
   "language": "python",
   "name": "fanbo_pykeen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
